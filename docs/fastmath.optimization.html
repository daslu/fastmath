<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>fastmath.optimization documentation</title><script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="highlight/solarized-light.css" /><script type="text/javascript" src="highlight/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a> with <a href="https://github.com/xsc/codox-theme-rdash">RDash UI</a> theme</h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Fastmath</span> <span class="project-version">2.1.9-SNAPSHOT</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>fastmath</span></div></div></li><li class="depth-2 branch"><a href="fastmath.clustering.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clustering</span></div></a></li><li class="depth-2 branch"><a href="fastmath.complex.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>complex</span></div></a></li><li class="depth-2 branch"><a href="fastmath.core.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>core</span></div></a></li><li class="depth-2 branch"><a href="fastmath.curves.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>curves</span></div></a></li><li class="depth-2 branch"><a href="fastmath.distance.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>distance</span></div></a></li><li class="depth-2 branch"><a href="fastmath.easings.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>easings</span></div></a></li><li class="depth-2 branch"><a href="fastmath.efloat.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>efloat</span></div></a></li><li class="depth-2 branch"><a href="fastmath.fields.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>fields</span></div></a></li><li class="depth-2 branch"><a href="fastmath.gp.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>gp</span></div></a></li><li class="depth-2 branch"><a href="fastmath.grid.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>grid</span></div></a></li><li class="depth-2 branch"><a href="fastmath.interpolation.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>interpolation</span></div></a></li><li class="depth-2 branch"><a href="fastmath.kernel.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>kernel</span></div></a></li><li class="depth-2 branch"><a href="fastmath.matrix.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>matrix</span></div></a></li><li class="depth-2 current"><a href="fastmath.optimization.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>optimization</span></div></a></li><li class="depth-3"><a href="fastmath.optimization.bo.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>bo</span></div></a></li><li class="depth-2"><a href="fastmath.protocols.html"><div class="inner"><span class="tree" style="top: -52px;"><span class="top" style="height: 61px;"></span><span class="bottom"></span></span><span>protocols</span></div></a></li><li class="depth-3"><a href="fastmath.protocols.matrix.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>matrix</span></div></a></li><li class="depth-2 branch"><a href="fastmath.random.html"><div class="inner"><span class="tree" style="top: -52px;"><span class="top" style="height: 61px;"></span><span class="bottom"></span></span><span>random</span></div></a></li><li class="depth-2 branch"><a href="fastmath.signal.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>signal</span></div></a></li><li class="depth-2 branch"><a href="fastmath.stats.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>stats</span></div></a></li><li class="depth-2 branch"><a href="fastmath.transform.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>transform</span></div></a></li><li class="depth-2"><a href="fastmath.vector.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>vector</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="fastmath.optimization.html#var-bayesian-optimization"><div class="inner"><span>bayesian-optimization</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-maximize"><div class="inner"><span>maximize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-maximizer"><div class="inner"><span>maximizer</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-minimize"><div class="inner"><span>minimize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-minimizer"><div class="inner"><span>minimizer</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-scan-and-maximize"><div class="inner"><span>scan-and-maximize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-scan-and-minimize"><div class="inner"><span>scan-and-minimize</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">fastmath.optimization</h1><div class="doc"><div class="markdown"><p>Optimization.</p>
<p>Namespace provides various optimization methods.</p>
<ul>
<li>Brent (1d functions)</li>
<li>Bobyqa (2d+ functions)</li>
<li>Powell</li>
<li>Nelder-Mead</li>
<li>Multidirectional simplex</li>
<li>CMAES</li>
<li>Gradient</li>
<li>Bayesian Optimization (see below)</li>
</ul>
<p>All optimizers require bounds.</p>
<h2><a href="#optimizers" id="optimizers"></a>Optimizers</h2>
<p>To optimize functions call one of the following functions:</p>
<ul>
<li><a href="fastmath.optimization.html#var-minimize">minimize</a> or <a href="fastmath.optimization.html#var-maximize">maximize</a> - to perform actual optimization</li>
<li><a href="fastmath.optimization.html#var-scan-and-minimize">scan-and-minimize</a> or <a href="fastmath.optimization.html#var-scan-and-maximize">scan-and-maximize</a> - functions find initial point using brute force and then perform optimization paralelly for best initialization points. Brute force scan is done using jitter low discrepancy sequence generator.</li>
</ul>
<p>You can also create optimizer (function which performs optimization) by calling <a href="fastmath.optimization.html#var-minimizer">minimizer</a> or <a href="fastmath.optimization.html#var-maximizer">maximizer</a>. Optimizer accepts initial point.</p>
<p>All above accept:</p>
<ul>
<li>one of the optimization method, ie: <code>:brent</code>, <code>:bobyqa</code>, <code>:nelder-mead</code>, <code>:multidirectional-simplex</code>, <code>:cmaes</code>, <code>:gradient</code></li>
<li>function to optimize</li>
<li>parameters as a map</li>
</ul>
<p>For parameters meaning refer <a href="https://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/index.html?org/apache/commons/math3/optim/package-summary.html">Optim package</a></p>
<h3><a href="#common-parameters" id="common-parameters"></a>Common parameters</h3>
<ul>
<li><code>:bounds</code> (obligatory) - search ranges for each dimensions as a seqence of <a href="low high">low high</a> pairs</li>
<li><code>:initial</code> - initial point other then mid of the bounds as vector</li>
<li><code>:max-evals</code> - maximum number of function evaluations</li>
<li><code>:max-iters</code> - maximum number of algorithm interations</li>
<li><code>:bounded?</code> - should optimizer force to keep search within bounds (some algorithms go outside desired ranges)</li>
<li><code>:stats?</code> - return number of iterations and evaluations along with result</li>
<li><code>:rel</code> and <code>:abs</code> - relative and absolute accepted errors</li>
</ul>
<p>For <code>scan-and-...</code> functions additionally you can provide:</p>
<ul>
<li><code>:N</code> - number of brute force iterations</li>
<li><code>:n</code> - fraction of N which are used as initial points to parallel optimization</li>
<li><code>:jitter</code> - jitter factor for sequence generator (for scanning domain)</li>
</ul>
<h3><a href="#specific-parameters" id="specific-parameters"></a>Specific parameters</h3>
<ul>
<li>BOBYQA - <code>:number-of-points</code>, <code>:initial-radius</code>, <code>:stopping-radius</code></li>
<li>Nelder-Mead - <code>:rho</code>, <code>:khi</code>, <code>:gamma</code>, <code>:sigma</code>, <code>:side-length</code></li>
<li>Multidirectional simples - <code>:khi</code>, <code>:gamma</code>, <code>:side-length</code></li>
<li>CMAES - <code>:check-feasable-count</code>, <code>:diagonal-only</code>, <code>:stop-fitness</code>, <code>:active-cma?</code>, <code>:population-size</code></li>
<li>Gradient - <code>:bracketing-range</code>, <code>:formula</code> (<code>:polak-ribiere</code> or <code>:fletcher-reeves</code>), <code>:gradient-h</code> (finite differentiation step, default: <code>0.01</code>)</li>
</ul>
<h2><a href="#bayesian-optimization" id="bayesian-optimization"></a>Bayesian Optimization</h2>
<p>Bayesian optimizer can be used for optimizing expensive to evaluate black box functions. Refer this <a href="http://krasserm.github.io/2018/03/21/bayesian-optimization/">article</a> or this <a href="https://nextjournal.com/a/LKqpdDdxiggRyHhqDG5FH?token=Ss1Qq3MzHWN8ZyEt9UC1ZZ">article</a></p>
</div><div class="markdown"><h4>Categories</h4><ul></ul><p>Other vars: <a href="fastmath.optimization.html#var-bayesian-optimization">bayesian-optimization</a> <a href="fastmath.optimization.html#var-maximize">maximize</a> <a href="fastmath.optimization.html#var-maximizer">maximizer</a> <a href="fastmath.optimization.html#var-minimize">minimize</a> <a href="fastmath.optimization.html#var-minimizer">minimizer</a> <a href="fastmath.optimization.html#var-scan-and-maximize">scan-and-maximize</a> <a href="fastmath.optimization.html#var-scan-and-minimize">scan-and-minimize</a></p></div></div><div class="public anchor" id="var-bayesian-optimization"><h3>bayesian-optimization</h3><div class="usage"><code>(bayesian-optimization f {:keys [warm-up init-points bounds utility-function-type utility-param kernel kscale jitter noise optimizer optimizer-params normalize?], :or {utility-function-type :ucb, init-points 3, jitter 0.25, noise 1.0E-8, utility-param (if (#{:ei :poi} utility-function-type) 0.001 2.576), warm-up (* (count bounds) 1000), normalize? true, kernel (k/kernel :mattern-52), kscale 1.0}})</code></div><div class="doc"><div class="markdown"><p>Bayesian optimizer</p>
<p>Parameters are:</p>
<ul>
<li><code>:warm-up</code> - number of brute force iterations to find maximum of utility function</li>
<li><code>:init-points</code> - number of initial evaluation before bayesian optimization starts. Points are selected using jittered low discrepancy sequence generator (see: <a href="fastmath.random.html#var-jittered-sequence-generator">jittered-sequence-generator</a></li>
<li><code>:bounds</code> - bounds for each dimension</li>
<li><code>:utility-function-type</code> - one of <code>:ei</code>, <code>:poi</code> or <code>:ucb</code></li>
<li><code>:utility-param</code> - parameter for utility function (kappa for <code>ucb</code> and xi for <code>ei</code> and <code>poi</code>)</li>
<li><code>:kernel</code> - kernel, default <code>:mattern-52</code>, see <a href="fastmath.kernel.html">fastmath.kernel</a></li>
<li><code>:kscale</code> - scaling factor for kernel</li>
<li><code>:jitter</code> - jitter factor for sequence generator (used to find initial points)</li>
<li><code>:noise</code> - noise (lambda) factor for gaussian process</li>
<li><code>:optimizer</code> - name of optimizer (used to optimized utility function)</li>
<li><code>:optimizer-params</code> - optional parameters for optimizer</li>
<li><code>:normalize?</code> - normalize data in gaussian process?</li>
</ul>
<p>Returns lazy sequence with consecutive executions. Each step consist:</p>
<ul>
<li><code>:x</code> - maximum <code>x</code></li>
<li><code>:y</code> - value</li>
<li><code>:xs</code> - list of all visited x’s</li>
<li><code>:ys</code> - list of values for every visited x</li>
<li><code>:gp</code> - current gaussian process regression instance</li>
<li><code>:util-fn</code> - current utility function</li>
<li><code>:util-best</code> - best x in utility function</li>
</ul>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  (nth (bayesian-optimization
        (fn [x y] (- (f x y)))
        {:bounds bounds, :init-points 5, :utility-function-type :poi})
       10))
;;=&gt; {:gp
;;=&gt;  #object[fastmath.gp.GaussianProcess 0x28b5ba47 "fastmath.gp.GaussianProcess@28b5ba47"],
;;=&gt;  :util-best (3.3729488879147964 -2.620438835444758),
;;=&gt;  :util-fn #<fn@56c734b fastmath.optimization="" ayesian_step_fn[fn]="">,
;;=&gt;  :x (3.3729488879147964 -2.620438835444758),
;;=&gt;  :xs ((3.3729488879147964 -2.620438835444758)
;;=&gt;       (3.36187557517831 -2.6237903194805474)
;;=&gt;       (3.351828505436199 -2.6264359739765966)
;;=&gt;       (3.3060837306516566 -2.640935863617064)
;;=&gt;       (3.286454362856877 -2.6473628941707936)
;;=&gt;       (3.265767305740245 -2.6544534772895774)
;;=&gt;       (3.2419800358378614 -2.6637697495855432)
;;=&gt;       (3.190317165852559 -2.684697918465639)
;;=&gt;       (3.172005847659775 -2.6921006238846394)
;;=&gt;       (3.1451516934935335 -2.7029851461345773)
;;=&gt;       (3.1427077525951934 -2.7039793547117545)
;;=&gt;       [-1.433722730094984 -4.137307884094992]
;;=&gt;       [-4.714882264268117 1.9098365364159786]
;;=&gt;       [3.1397031994440194 -2.7052550947300946]
;;=&gt;       [0.4479931778387405 2.8837298590521643]
;;=&gt;       [-2.031539012553959 -1.389874414200587]),
;;=&gt;  :y -15.52930903134845,
;;=&gt;  :ys (-15.52930903134845
;;=&gt;       -15.927245046746147
;;=&gt;       -16.282604887285657
;;=&gt;       -18.110651852307072
;;=&gt;       -18.959945083044893
;;=&gt;       -19.904039697074026
;;=&gt;       -21.083425811017257
;;=&gt;       -23.841924184622968
;;=&gt;       -24.872757395829396
;;=&gt;       -26.435102867433862
;;=&gt;       -26.580321983031297
;;=&gt;       -246.53690626818835
;;=&gt;       -237.7413705814692
;;=&gt;       -26.76191499591264
;;=&gt;       -65.76759583573417
;;=&gt;       -118.67959361768936)}</fn@56c734b></code></pre></div><div><blockquote><p>Bayesian optimization points</p>
</blockquote><img src="images/o/bo.jpg" /></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L486">view source</a></div></div><div class="public anchor" id="var-maximize"><h3>maximize</h3><div class="usage"><code>(maximize method f config)</code></div><div class="doc"><div class="markdown"><p>Maximize given function.</p>
<p>Parameters: optimization method, function and configuration.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (maximize :powell f {:bounds bounds}),
   :brent (maximize :brent f {:bounds bounds}),
   :bfgs (maximize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(-0.4523106913336431) 7.224689671203531],
;;=&gt;  :brent [(-0.4523106823170646) 7.224689671203529],
;;=&gt;  :powell [(-0.4522927913307559) 7.224689666542709]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L368">view source</a></div></div><div class="public anchor" id="var-maximizer"><h3>maximizer</h3><div class="usage"><code>(maximizer method f config)</code></div><div class="doc"><div class="markdown"><p>Create optimizer which maximizer function.</p>
<p>Returns function which performs optimization for optionally given initial point.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))
      optimizer (maximizer :cmaes f {:bounds bounds})]
  {:optimizer optimizer,
   :run-1 (optimizer),
   :run-2 (optimizer [4.5]),
   :run-3 (optimizer [-4.5])})
;;=&gt; {:optimizer #<fn@790c2af1 fastmath.optimization="" ptimizer[fn]="">,
;;=&gt;  :run-1 [(-0.17915749236498976) 6.517287720905591],
;;=&gt;  :run-2 [(0.6671021467828373) 2.227512773020161],
;;=&gt;  :run-3 [(-0.9516825400712801) 6.139029174147362]}</fn@790c2af1></code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L353">view source</a></div></div><div class="public anchor" id="var-minimize"><h3>minimize</h3><div class="usage"><code>(minimize method f config)</code></div><div class="doc"><div class="markdown"><p>Minimize given function.</p>
<p>Parameters: optimization method, function and configuration.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>1d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (minimize :powell f {:bounds bounds}),
   :brent (minimize :brent f {:bounds bounds}),
   :brent-with-initial-point
   (minimize :brent f {:bounds bounds, :initial [2.0]})})
;;=&gt; {:brent [(-3.947569586073323) 2.2959519482739297],
;;=&gt;  :brent-with-initial-point [(2.979593427579756) -0.20178173314322778],
;;=&gt;  :powell [(2.3572022329682807) -0.23501046849989368]}</code></pre></div><div><blockquote><p>2d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  {:bobyqa (minimize :bobyqa f {:bounds bounds}),
   :gradient (minimize :gradient f {:bounds bounds}),
   :bfgs (minimize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(2.9999999998534097 1.9999999988326103) 2.7385222287082803E-17],
;;=&gt;  :bobyqa [(3.5844283403693833 -1.848126526921083)
;;=&gt;           1.1846390625694734E-19],
;;=&gt;  :gradient [(2.999999970879802 2.0000000603184582)
;;=&gt;             5.80971508134794E-14]}</code></pre></div><div><blockquote><p>With stats</p>
</blockquote><pre><code class="hljs clojure">(minimize :gradient
          (fn* [p1__33957#] (m/sin p1__33957#))
          {:bounds [[-5 5]], :stats? true})
;;=&gt; {:evaluations 22, :iterations 3, :result [(-1.5707963273466874) -1.0]}</code></pre></div><div><blockquote><p>min/max of f using <code>:powell</code> optimizer</p>
</blockquote><img src="images/o/powell-1d.png" /></div><div><blockquote><p>min/max of f using <code>:nelder-mead</code> optimizer</p>
</blockquote><img src="images/o/nelder-mead-1d.png" /></div><div><blockquote><p>min/max of f using <code>:multidirectional-simplex</code> optimizer</p>
</blockquote><img src="images/o/multidirectional-simplex-1d.png" /></div><div><blockquote><p>min/max of f using <code>:cmaes</code> optimizer</p>
</blockquote><img src="images/o/cmaes-1d.png" /></div><div><blockquote><p>min/max of f using <code>:gradient</code> optimizer</p>
</blockquote><img src="images/o/gradient-1d.png" /></div><div><blockquote><p>min/max of f using <code>:brent</code> optimizer</p>
</blockquote><img src="images/o/brent-1d.png" /></div><div><blockquote><p>min/max of f using <code>:powell</code> optimizer</p>
</blockquote><img src="images/o/powell-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:nelder-mead</code> optimizer</p>
</blockquote><img src="images/o/nelder-mead-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:multidirectional-simplex</code> optimizer</p>
</blockquote><img src="images/o/multidirectional-simplex-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:cmaes</code> optimizer</p>
</blockquote><img src="images/o/cmaes-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:gradient</code> optimizer</p>
</blockquote><img src="images/o/gradient-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:bobyqa</code> optimizer</p>
</blockquote><img src="images/o/bobyqa-2d.jpg" /></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L362">view source</a></div></div><div class="public anchor" id="var-minimizer"><h3>minimizer</h3><div class="usage"><code>(minimizer method f config)</code></div><div class="doc"><div class="markdown"><p>Create optimizer which minimizes function.</p>
<p>Returns function which performs optimization for optionally given initial point.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))
      optimizer (minimizer :brent f {:bounds bounds})]
  {:optimizer optimizer,
   :run-1 (optimizer),
   :run-2 (optimizer [4.5]),
   :run-3 (optimizer [-4.5])})
;;=&gt; {:optimizer #<fn@4412c998 fastmath.optimization="" ptimizer[fn]="">,
;;=&gt;  :run-1 [(-3.947569586073323) 2.2959519482739297],
;;=&gt;  :run-2 [(2.357114991599655) -0.2350104692683484],
;;=&gt;  :run-3 [(-4.570514545168775) 2.074718566761628]}</fn@4412c998></code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L347">view source</a></div></div><div class="public anchor" id="var-scan-and-maximize"><h3>scan-and-maximize</h3><div class="usage"></div><div class="doc"><div class="markdown"></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (scan-and-maximize :powell f {:bounds bounds}),
   :brent (scan-and-maximize :brent f {:bounds bounds}),
   :bfgs (scan-and-maximize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(-0.4523106924983422) 7.224689671203531],
;;=&gt;  :brent [(-0.4523106952522764) 7.224689671203531],
;;=&gt;  :powell [(-0.45230980862870857) 7.224689671192147]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L420">view source</a></div></div><div class="public anchor" id="var-scan-and-minimize"><h3>scan-and-minimize</h3><div class="usage"></div><div class="doc"><div class="markdown"></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>1d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (scan-and-minimize :powell f {:bounds bounds}),
   :brent (scan-and-minimize :brent f {:bounds bounds}),
   :bfgs (scan-and-minimize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(2.35711490562854) -0.23501046926842561],
;;=&gt;  :brent [(2.357114837258413) -0.23501046926837937],
;;=&gt;  :powell [(2.3567778686638596) -0.23501046922629149]}</code></pre></div><div><blockquote><p>2d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  {:bobyqa (scan-and-minimize :bobyqa f {:bounds bounds}),
   :gradient (scan-and-minimize :gradient f {:bounds bounds}),
   :bfgs (scan-and-minimize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(2.999999998925092 1.99999999832212) 1.2668195871859995E-16],
;;=&gt;  :bobyqa [(2.9999999999935567 2.000000000056682)
;;=&gt;           4.8850752449334874E-20],
;;=&gt;  :gradient [(-2.80511808703194 3.1313125185420416)
;;=&gt;             3.590446894468834E-18]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L419">view source</a></div></div></div></body></html>