<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>fastmath.optimization documentation</title><script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="highlight/solarized-light.css" /><script type="text/javascript" src="highlight/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a> with <a href="https://github.com/xsc/codox-theme-rdash">RDash UI</a> theme</h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Fastmath</span> <span class="project-version">2.1.9-SNAPSHOT</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>fastmath</span></div></div></li><li class="depth-2 branch"><a href="fastmath.clustering.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clustering</span></div></a></li><li class="depth-2 branch"><a href="fastmath.complex.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>complex</span></div></a></li><li class="depth-2 branch"><a href="fastmath.core.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>core</span></div></a></li><li class="depth-2 branch"><a href="fastmath.curves.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>curves</span></div></a></li><li class="depth-2 branch"><a href="fastmath.distance.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>distance</span></div></a></li><li class="depth-2 branch"><a href="fastmath.easings.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>easings</span></div></a></li><li class="depth-2 branch"><a href="fastmath.efloat.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>efloat</span></div></a></li><li class="depth-2 branch"><a href="fastmath.fields.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>fields</span></div></a></li><li class="depth-2 branch"><a href="fastmath.gp.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>gp</span></div></a></li><li class="depth-2 branch"><a href="fastmath.grid.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>grid</span></div></a></li><li class="depth-2 branch"><a href="fastmath.interpolation.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>interpolation</span></div></a></li><li class="depth-2 branch"><a href="fastmath.kernel.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>kernel</span></div></a></li><li class="depth-2 branch"><a href="fastmath.matrix.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>matrix</span></div></a></li><li class="depth-2 current"><a href="fastmath.optimization.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>optimization</span></div></a></li><li class="depth-3"><a href="fastmath.optimization.bo.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>bo</span></div></a></li><li class="depth-2"><a href="fastmath.protocols.html"><div class="inner"><span class="tree" style="top: -52px;"><span class="top" style="height: 61px;"></span><span class="bottom"></span></span><span>protocols</span></div></a></li><li class="depth-3"><a href="fastmath.protocols.matrix.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>matrix</span></div></a></li><li class="depth-2 branch"><a href="fastmath.random.html"><div class="inner"><span class="tree" style="top: -52px;"><span class="top" style="height: 61px;"></span><span class="bottom"></span></span><span>random</span></div></a></li><li class="depth-2 branch"><a href="fastmath.signal.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>signal</span></div></a></li><li class="depth-2 branch"><a href="fastmath.stats.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>stats</span></div></a></li><li class="depth-2 branch"><a href="fastmath.transform.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>transform</span></div></a></li><li class="depth-2"><a href="fastmath.vector.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>vector</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="fastmath.optimization.html#var-bayesian-optimization"><div class="inner"><span>bayesian-optimization</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-maximize"><div class="inner"><span>maximize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-maximizer"><div class="inner"><span>maximizer</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-minimize"><div class="inner"><span>minimize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-minimizer"><div class="inner"><span>minimizer</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-scan-and-maximize"><div class="inner"><span>scan-and-maximize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-scan-and-minimize"><div class="inner"><span>scan-and-minimize</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">fastmath.optimization</h1><div class="doc"><div class="markdown"><p>Optimization.</p>
<p>Namespace provides various optimization methods.</p>
<ul>
<li>Brent (1d functions)</li>
<li>Bobyqa (2d+ functions)</li>
<li>Powell</li>
<li>Nelder-Mead</li>
<li>Multidirectional simplex</li>
<li>CMAES</li>
<li>Gradient</li>
<li>Bayesian Optimization (see below)</li>
</ul>
<p>All optimizers require bounds.</p>
<h2><a href="#optimizers" id="optimizers"></a>Optimizers</h2>
<p>To optimize functions call one of the following functions:</p>
<ul>
<li><a href="fastmath.optimization.html#var-minimize">minimize</a> or <a href="fastmath.optimization.html#var-maximize">maximize</a> - to perform actual optimization</li>
<li><a href="fastmath.optimization.html#var-scan-and-minimize">scan-and-minimize</a> or <a href="fastmath.optimization.html#var-scan-and-maximize">scan-and-maximize</a> - functions find initial point using brute force and then perform optimization paralelly for best initialization points. Brute force scan is done using jitter low discrepancy sequence generator.</li>
</ul>
<p>You can also create optimizer (function which performs optimization) by calling <a href="fastmath.optimization.html#var-minimizer">minimizer</a> or <a href="fastmath.optimization.html#var-maximizer">maximizer</a>. Optimizer accepts initial point.</p>
<p>All above accept:</p>
<ul>
<li>one of the optimization method, ie: <code>:brent</code>, <code>:bobyqa</code>, <code>:nelder-mead</code>, <code>:multidirectional-simplex</code>, <code>:cmaes</code>, <code>:gradient</code></li>
<li>function to optimize</li>
<li>parameters as a map</li>
</ul>
<p>For parameters meaning refer <a href="https://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/index.html?org/apache/commons/math3/optim/package-summary.html">Optim package</a></p>
<h3><a href="#common-parameters" id="common-parameters"></a>Common parameters</h3>
<ul>
<li><code>:bounds</code> (obligatory) - search ranges for each dimensions as a seqence of <a href="low high">low high</a> pairs</li>
<li><code>:initial</code> - initial point other then mid of the bounds as vector</li>
<li><code>:max-evals</code> - maximum number of function evaluations</li>
<li><code>:max-iters</code> - maximum number of algorithm interations</li>
<li><code>:bounded?</code> - should optimizer force to keep search within bounds (some algorithms go outside desired ranges)</li>
<li><code>:stats?</code> - return number of iterations and evaluations along with result</li>
<li><code>:rel</code> and <code>:abs</code> - relative and absolute accepted errors</li>
</ul>
<p>For <code>scan-and-...</code> functions additionally you can provide:</p>
<ul>
<li><code>:N</code> - number of brute force iterations</li>
<li><code>:n</code> - fraction of N which are used as initial points to parallel optimization</li>
<li><code>:jitter</code> - jitter factor for sequence generator (for scanning domain)</li>
</ul>
<h3><a href="#specific-parameters" id="specific-parameters"></a>Specific parameters</h3>
<ul>
<li>BOBYQA - <code>:number-of-points</code>, <code>:initial-radius</code>, <code>:stopping-radius</code></li>
<li>Nelder-Mead - <code>:rho</code>, <code>:khi</code>, <code>:gamma</code>, <code>:sigma</code>, <code>:side-length</code></li>
<li>Multidirectional simples - <code>:khi</code>, <code>:gamma</code>, <code>:side-length</code></li>
<li>CMAES - <code>:check-feasable-count</code>, <code>:diagonal-only</code>, <code>:stop-fitness</code>, <code>:active-cma?</code>, <code>:population-size</code></li>
<li>Gradient - <code>:bracketing-range</code>, <code>:formula</code> (<code>:polak-ribiere</code> or <code>:fletcher-reeves</code>), <code>:gradient-h</code> (finite differentiation step, default: <code>0.01</code>)</li>
</ul>
<h2><a href="#bayesian-optimization" id="bayesian-optimization"></a>Bayesian Optimization</h2>
<p>Bayesian optimizer can be used for optimizing expensive to evaluate black box functions. Refer this <a href="http://krasserm.github.io/2018/03/21/bayesian-optimization/">article</a> or this <a href="https://nextjournal.com/a/LKqpdDdxiggRyHhqDG5FH?token=Ss1Qq3MzHWN8ZyEt9UC1ZZ">article</a></p>
</div><div class="markdown"><h4>Categories</h4><ul></ul><p>Other vars: <a href="fastmath.optimization.html#var-bayesian-optimization">bayesian-optimization</a> <a href="fastmath.optimization.html#var-maximize">maximize</a> <a href="fastmath.optimization.html#var-maximizer">maximizer</a> <a href="fastmath.optimization.html#var-minimize">minimize</a> <a href="fastmath.optimization.html#var-minimizer">minimizer</a> <a href="fastmath.optimization.html#var-scan-and-maximize">scan-and-maximize</a> <a href="fastmath.optimization.html#var-scan-and-minimize">scan-and-minimize</a></p></div></div><div class="public anchor" id="var-bayesian-optimization"><h3>bayesian-optimization</h3><div class="usage"><code>(bayesian-optimization f {:keys [warm-up init-points bounds utility-function-type utility-param kernel kscale jitter noise optimizer optimizer-params normalize?], :or {utility-function-type :ucb, init-points 3, jitter 0.25, noise 1.0E-8, utility-param (if (#{:ei :poi} utility-function-type) 0.001 2.576), warm-up (* (count bounds) 1000), normalize? true, kernel (k/kernel :mattern-52), kscale 1.0}})</code></div><div class="doc"><div class="markdown"><p>Bayesian optimizer</p>
<p>Parameters are:</p>
<ul>
<li><code>:warm-up</code> - number of brute force iterations to find maximum of utility function</li>
<li><code>:init-points</code> - number of initial evaluation before bayesian optimization starts. Points are selected using jittered low discrepancy sequence generator (see: <a href="fastmath.random.html#var-jittered-sequence-generator">jittered-sequence-generator</a></li>
<li><code>:bounds</code> - bounds for each dimension</li>
<li><code>:utility-function-type</code> - one of <code>:ei</code>, <code>:poi</code> or <code>:ucb</code></li>
<li><code>:utility-param</code> - parameter for utility function (kappa for <code>ucb</code> and xi for <code>ei</code> and <code>poi</code>)</li>
<li><code>:kernel</code> - kernel, default <code>:mattern-52</code>, see <a href="fastmath.kernel.html">fastmath.kernel</a></li>
<li><code>:kscale</code> - scaling factor for kernel</li>
<li><code>:jitter</code> - jitter factor for sequence generator (used to find initial points)</li>
<li><code>:noise</code> - noise (lambda) factor for gaussian process</li>
<li><code>:optimizer</code> - name of optimizer (used to optimized utility function)</li>
<li><code>:optimizer-params</code> - optional parameters for optimizer</li>
<li><code>:normalize?</code> - normalize data in gaussian process?</li>
</ul>
<p>Returns lazy sequence with consecutive executions. Each step consist:</p>
<ul>
<li><code>:x</code> - maximum <code>x</code></li>
<li><code>:y</code> - value</li>
<li><code>:xs</code> - list of all visited x’s</li>
<li><code>:ys</code> - list of values for every visited x</li>
<li><code>:gp</code> - current gaussian process regression instance</li>
<li><code>:util-fn</code> - current utility function</li>
<li><code>:util-best</code> - best x in utility function</li>
</ul>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  (nth (bayesian-optimization
        (fn [x y] (- (f x y)))
        {:bounds bounds, :init-points 5, :utility-function-type :poi})
       10))
;;=&gt; {:gp
;;=&gt;  #object[fastmath.gp.GaussianProcess 0x7a550ab8 "fastmath.gp.GaussianProcess@7a550ab8"],
;;=&gt;  :util-best (3.291333294896285 -2.6054325784083123),
;;=&gt;  :util-fn #<fn@6952b0b2 fastmath.optimization="" ayesian_step_fn[fn]="">,
;;=&gt;  :x (3.291333294896285 -2.6054325784083123),
;;=&gt;  :xs ((3.291333294896285 -2.6054325784083123)
;;=&gt;       (3.2700855899497467 -2.6313459137193185)
;;=&gt;       (3.2507573094282725 -2.64669287090491)
;;=&gt;       (3.1953754560142986 -2.6688524723606957)
;;=&gt;       (3.1747125029332914 -2.673338452217369)
;;=&gt;       (3.1107352232152716 -2.6813622017940903)
;;=&gt;       (3.085493876269251 -2.682277852574876)
;;=&gt;       (3.003762279333165 -2.673348685039945)
;;=&gt;       (2.9727849257332997 -2.667087384147544)
;;=&gt;       (2.926026971013217 -2.6548689179696527)
;;=&gt;       (2.922832649441141 -2.6540449706977607)
;;=&gt;       [-2.0726293271051084 -2.922482917894412]
;;=&gt;       [-4.409659206174903 2.0557707705011765]
;;=&gt;       [2.9185583711435825 -2.652834510263868]
;;=&gt;       [0.29469397324186275 2.836848260243544]
;;=&gt;       [-1.939063018801864 -1.441523324894094]),
;;=&gt;  :y -17.1710877105082,
;;=&gt;  :ys (-17.1710877105082
;;=&gt;       -18.833238429535996
;;=&gt;       -20.0817483736445
;;=&gt;       -22.97083801138222
;;=&gt;       -23.95274708224506
;;=&gt;       -26.930424728522915
;;=&gt;       -28.081399702162372
;;=&gt;       -31.55557630056177
;;=&gt;       -32.84965553786266
;;=&gt;       -34.787836882773625
;;=&gt;       -34.92511189360465
;;=&gt;       -92.95590098720464
;;=&gt;       -161.87034764986095
;;=&gt;       -35.105164392607854
;;=&gt;       -67.02878121574781
;;=&gt;       -122.44377804391632)}</fn@6952b0b2></code></pre></div><div><blockquote><p>Bayesian optimization points</p>
</blockquote><img src="images/o/bo.jpg" /></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L486">view source</a></div></div><div class="public anchor" id="var-maximize"><h3>maximize</h3><div class="usage"><code>(maximize method f config)</code></div><div class="doc"><div class="markdown"><p>Maximize given function.</p>
<p>Parameters: optimization method, function and configuration.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (maximize :powell f {:bounds bounds}),
   :brent (maximize :brent f {:bounds bounds}),
   :bfgs (maximize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(-0.4523106913336431) 7.224689671203531],
;;=&gt;  :brent [(-0.4523106823170646) 7.224689671203529],
;;=&gt;  :powell [(-0.4522927913307559) 7.224689666542709]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L368">view source</a></div></div><div class="public anchor" id="var-maximizer"><h3>maximizer</h3><div class="usage"><code>(maximizer method f config)</code></div><div class="doc"><div class="markdown"><p>Create optimizer which maximizer function.</p>
<p>Returns function which performs optimization for optionally given initial point.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))
      optimizer (maximizer :cmaes f {:bounds bounds})]
  {:optimizer optimizer,
   :run-1 (optimizer),
   :run-2 (optimizer [4.5]),
   :run-3 (optimizer [-4.5])})
;;=&gt; {:optimizer #<fn@518a9f60 fastmath.optimization="" ptimizer[fn]="">,
;;=&gt;  :run-1 [(0.0) 6.0],
;;=&gt;  :run-2 [(-1.6730851954778103) 4.688668216572202],
;;=&gt;  :run-3 [(-4.5) 2.1239369421519996]}</fn@518a9f60></code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L353">view source</a></div></div><div class="public anchor" id="var-minimize"><h3>minimize</h3><div class="usage"><code>(minimize method f config)</code></div><div class="doc"><div class="markdown"><p>Minimize given function.</p>
<p>Parameters: optimization method, function and configuration.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>1d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (minimize :powell f {:bounds bounds}),
   :brent (minimize :brent f {:bounds bounds}),
   :brent-with-initial-point
   (minimize :brent f {:bounds bounds, :initial [2.0]})})
;;=&gt; {:brent [(-3.947569586073323) 2.2959519482739297],
;;=&gt;  :brent-with-initial-point [(2.979593427579756) -0.20178173314322778],
;;=&gt;  :powell [(2.3572022329682807) -0.23501046849989368]}</code></pre></div><div><blockquote><p>2d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  {:bobyqa (minimize :bobyqa f {:bounds bounds}),
   :gradient (minimize :gradient f {:bounds bounds}),
   :bfgs (minimize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(2.9999999998534097 1.9999999988326103) 2.7385222287082803E-17],
;;=&gt;  :bobyqa [(3.5844283403693833 -1.848126526921083)
;;=&gt;           1.1846390625694734E-19],
;;=&gt;  :gradient [(2.999999970879802 2.0000000603184582)
;;=&gt;             5.80971508134794E-14]}</code></pre></div><div><blockquote><p>With stats</p>
</blockquote><pre><code class="hljs clojure">(minimize :gradient
          (fn* [p1__33977#] (m/sin p1__33977#))
          {:bounds [[-5 5]], :stats? true})
;;=&gt; {:evaluations 22, :iterations 3, :result [(-1.5707963273466874) -1.0]}</code></pre></div><div><blockquote><p>min/max of f using <code>:powell</code> optimizer</p>
</blockquote><img src="images/o/powell-1d.png" /></div><div><blockquote><p>min/max of f using <code>:nelder-mead</code> optimizer</p>
</blockquote><img src="images/o/nelder-mead-1d.png" /></div><div><blockquote><p>min/max of f using <code>:multidirectional-simplex</code> optimizer</p>
</blockquote><img src="images/o/multidirectional-simplex-1d.png" /></div><div><blockquote><p>min/max of f using <code>:cmaes</code> optimizer</p>
</blockquote><img src="images/o/cmaes-1d.png" /></div><div><blockquote><p>min/max of f using <code>:gradient</code> optimizer</p>
</blockquote><img src="images/o/gradient-1d.png" /></div><div><blockquote><p>min/max of f using <code>:brent</code> optimizer</p>
</blockquote><img src="images/o/brent-1d.png" /></div><div><blockquote><p>min/max of f using <code>:powell</code> optimizer</p>
</blockquote><img src="images/o/powell-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:nelder-mead</code> optimizer</p>
</blockquote><img src="images/o/nelder-mead-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:multidirectional-simplex</code> optimizer</p>
</blockquote><img src="images/o/multidirectional-simplex-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:cmaes</code> optimizer</p>
</blockquote><img src="images/o/cmaes-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:gradient</code> optimizer</p>
</blockquote><img src="images/o/gradient-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:bobyqa</code> optimizer</p>
</blockquote><img src="images/o/bobyqa-2d.jpg" /></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L362">view source</a></div></div><div class="public anchor" id="var-minimizer"><h3>minimizer</h3><div class="usage"><code>(minimizer method f config)</code></div><div class="doc"><div class="markdown"><p>Create optimizer which minimizes function.</p>
<p>Returns function which performs optimization for optionally given initial point.</p>
</div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))
      optimizer (minimizer :brent f {:bounds bounds})]
  {:optimizer optimizer,
   :run-1 (optimizer),
   :run-2 (optimizer [4.5]),
   :run-3 (optimizer [-4.5])})
;;=&gt; {:optimizer #<fn@6e31c2ad fastmath.optimization="" ptimizer[fn]="">,
;;=&gt;  :run-1 [(-3.947569586073323) 2.2959519482739297],
;;=&gt;  :run-2 [(2.357114991599655) -0.2350104692683484],
;;=&gt;  :run-3 [(-4.570514545168775) 2.074718566761628]}</fn@6e31c2ad></code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L347">view source</a></div></div><div class="public anchor" id="var-scan-and-maximize"><h3>scan-and-maximize</h3><div class="usage"></div><div class="doc"><div class="markdown"></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (scan-and-maximize :powell f {:bounds bounds}),
   :brent (scan-and-maximize :brent f {:bounds bounds}),
   :bfgs (scan-and-maximize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(-0.452310687244788) 7.22468967120353],
;;=&gt;  :brent [(-0.4523106925237113) 7.224689671203531],
;;=&gt;  :powell [(-0.4522695401226795) 7.2246896465734896]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L420">view source</a></div></div><div class="public anchor" id="var-scan-and-minimize"><h3>scan-and-minimize</h3><div class="usage"></div><div class="doc"><div class="markdown"></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>1d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (scan-and-minimize :powell f {:bounds bounds}),
   :brent (scan-and-minimize :brent f {:bounds bounds}),
   :bfgs (scan-and-minimize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(2.3571149047692392) -0.23501046926842556],
;;=&gt;  :brent [(2.357114950903574) -0.23501046926840366],
;;=&gt;  :powell [(2.357114809837623) -0.23501046926833416]}</code></pre></div><div><blockquote><p>2d function</p>
</blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  {:bobyqa (scan-and-minimize :bobyqa f {:bounds bounds}),
   :gradient (scan-and-minimize :gradient f {:bounds bounds}),
   :bfgs (scan-and-minimize :bfgs f {:bounds bounds})})
;;=&gt; {:bfgs [(2.999999957234398 2.0000000912223026) 1.3111129384607293E-13],
;;=&gt;  :bobyqa [(2.9999999999935567 2.000000000056682)
;;=&gt;           4.8850752449334874E-20],
;;=&gt;  :gradient [(3.5844283402670514 -1.8481265277590655)
;;=&gt;             9.820048195276188E-18]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L419">view source</a></div></div></div></body></html>